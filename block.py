import cv2
import time
import threading
import RPi.GPIO as GPIO
from ultralytics import YOLO

# === YOLO ëª¨ë¸ ë¡œë“œ ===
model = YOLO("best2.onnx")
CLASS_NAMES = ["ì ìë¸”ëŸ­", "ì„ í˜•ë¸”ëŸ­"]

# === ì „ì—­ ë³€ìˆ˜ ===
frame = None
last_annotated_frame = None
running = True
inference_interval_sec = 1.0
last_inference_time = 0
current_state = "NONE"  # STOP, GO_FORWARD, NONE
distance1 = 999.0
distance2 = 999.0
brake_engaged = False

# === í•€ ì„¤ì • ===
TRIG1 = 12
ECHO1 = 16
TRIG2 = 17
ECHO2 = 27
BUZZER = 18
SERVO_PIN = 26

GPIO.setmode(GPIO.BCM)
GPIO.setup(TRIG1, GPIO.OUT)
GPIO.setup(ECHO1, GPIO.IN)
GPIO.setup(TRIG2, GPIO.OUT)
GPIO.setup(ECHO2, GPIO.IN)
GPIO.setup(BUZZER, GPIO.OUT)
GPIO.setup(SERVO_PIN, GPIO.OUT)
GPIO.output(TRIG1, False)
GPIO.output(TRIG2, False)

# === ì„œë³´ëª¨í„° PWM ì„¤ì • ===
servo_pwm = GPIO.PWM(SERVO_PIN, 50)
servo_pwm.start(0)

# === ê±°ë¦¬ ì¸¡ì • í•¨ìˆ˜ ===
def get_distance(trig_pin, echo_pin):
    GPIO.output(trig_pin, False)
    time.sleep(0.05)
    GPIO.output(trig_pin, True)
    time.sleep(0.00001)
    GPIO.output(trig_pin, False)

    pulse_start = time.time()
    timeout = pulse_start + 0.04
    while GPIO.input(echo_pin) == 0:
        pulse_start = time.time()
        if pulse_start > timeout:
            return 999.0

    while GPIO.input(echo_pin) == 1:
        pulse_end = time.time()
        if pulse_end - pulse_start > 0.04:
            return 999.0

    pulse_duration = pulse_end - pulse_start
    distance = pulse_duration * 17150
    return round(distance, 2)

# === ë¶€ì € í•¨ìˆ˜ ===
def beep(frequency=1000, duration=0.1):
    pwm = GPIO.PWM(BUZZER, frequency)
    pwm.start(50)
    time.sleep(duration)
    pwm.stop()

# === ì„œë³´ ê°ë„ ì„¤ì • í•¨ìˆ˜ ===
def set_servo_angle(angle):
    duty = 2 + (angle / 18)
    servo_pwm.ChangeDutyCycle(duty)
    time.sleep(0.3)
    servo_pwm.ChangeDutyCycle(0)

# === ì¹´ë©”ë¼ ì“°ë ˆë“œ ===
def capture_thread():
    global frame, running
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    while running:
        ret, f = cap.read()
        if ret:
            frame = f.copy()
        else:
            print("âŒ Failed to capture frame")
            break
    cap.release()

# === ì´ˆìŒíŒŒ ê±°ë¦¬ ì“°ë ˆë“œ ===
def distance_thread():
    global distance1, distance2, running
    while running:
        try:
            distance1 = get_distance(TRIG1, ECHO1)
            distance2 = get_distance(TRIG2, ECHO2)
        except:
            distance1 = 999.0
            distance2 = 999.0
        time.sleep(0.1)

# === ë¶€ì € ì“°ë ˆë“œ ===
def buzzer_thread():
    global current_state, running
    while running:
        try:
            if current_state == "STOP":
                beep(1000, 0.1)
                time.sleep(0.1)
            elif current_state == "GO_FORWARD":
                beep(700, 0.05)
                time.sleep(2)
            else:
                min_dist = min(distance1, distance2)
                if min_dist < 30:
                    beep(900, 0.1)
                    time.sleep(0.1)
                elif min_dist < 70:
                    beep(900, 0.1)
                    time.sleep(0.5)
                elif min_dist < 100:
                    beep(900, 0.1)
                    time.sleep(1.0)
                else:
                    time.sleep(0.2)
        except:
            time.sleep(0.2)

# === ì“°ë ˆë“œ ì‹¤í–‰ ===
threading.Thread(target=capture_thread, daemon=True).start()
threading.Thread(target=distance_thread, daemon=True).start()
threading.Thread(target=buzzer_thread, daemon=True).start()

# === ë©”ì¸ ë£¨í”„ ===
try:
    print("ğŸš˜ ì‹œìŠ¤í…œ ì‹œì‘ (Ctrl+Cë¡œ ì¢…ë£Œ)")
    while True:
        if frame is None:
            continue

        now = time.time()
        if now - last_inference_time >= inference_interval_sec:
            last_inference_time = now
            input_frame = cv2.resize(frame, (640, 480))
            try:
                results = model(input_frame, verbose=False)
                last_annotated_frame = results[0].plot()
                boxes = results[0].boxes
                detected_classes = []

                for cls_id, conf in zip(boxes.cls.tolist(), boxes.conf.tolist()):
                    if conf >= 0.5:
                        class_name = CLASS_NAMES[int(cls_id)]
                        detected_classes.append(class_name)

                if "ì„ í˜•ë¸”ëŸ­" in detected_classes:
                    current_state = "STOP"
                elif "ì ìë¸”ëŸ­" in detected_classes:
                    current_state = "GO_FORWARD"
                else:
                    current_state = "NONE"

                # âœ… ìµœì†Œ ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ë¸Œë ˆì´í¬ ì‘ë™
                min_dist = min(distance1, distance2)
                if min_dist < 30 and not brake_engaged:
                    print("ğŸ›‘ ê¸´ê¸‰ ì œë™! (ì„œë³´ 90ë„)")
                    set_servo_angle(90)
                    brake_engaged = True
                elif min_dist >= 30 and brake_engaged:
                    print("âœ… ë¸Œë ˆì´í¬ í•´ì œ (ì„œë³´ 0ë„)")
                    set_servo_angle(0)
                    brake_engaged = False

                brake_status = "ê¸´ê¸‰ì œë™" if brake_engaged else "NONE"
                print(f"YOLO ì¶”ë¡  ì‹œê°„: {time.time() - now:.2f}ì´ˆ | ìƒíƒœ: {current_state} | ê±°ë¦¬1: {distance1}cm, ê±°ë¦¬2: {distance2}cm | ë¸Œë ˆì´í¬: {brake_status}")

            except Exception as e:
                print("âŒ YOLO ì¶”ë¡  ì˜¤ë¥˜:", e)
                current_state = "NONE"

        display_frame = last_annotated_frame if last_annotated_frame is not None else frame
        cv2.imshow("YOLO Real-Time View", display_frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            running = False
            break

finally:
    print("ğŸ›‘ í”„ë¡œê·¸ë¨ ì¢…ë£Œ")
    cv2.destroyAllWindows()
    servo_pwm.stop()
    GPIO.cleanup()